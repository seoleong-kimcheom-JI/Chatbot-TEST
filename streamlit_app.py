import os
import tempfile
import streamlit as st

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_community.utilities import SerpAPIWrapper

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.tools.retriever import create_retriever_tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_tool_calling_agent, AgentExecutor, Tool

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

def search_web():
    search = SerpAPIWrapper()
    def run_with_source(query: str) -> str:
        results = search.results(query)
        organic = results.get("organic_results", []) if isinstance(results, dict) else []
        formatted = []
        for r in organic[:5]:
            title = r.get("title")
            link = r.get("link")
            source = r.get("source") or r.get("displayed_link") or ""
            snippet = r.get("snippet") or ""
            if link:
                formatted.append(f"- [{title}]({link}) ({source})\n  {snippet}")
            else:
                formatted.append(f"- {title} (ì¶œì²˜: {source})\n  {snippet}")
        return "\n".join(formatted) if formatted else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    return Tool(name="web_search", func=run_with_source,
                description="ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë° ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

def load_pdf_files(uploaded_files):
    all_documents = []
    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name
        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        all_documents.extend(documents)

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = splitter.split_documents(all_documents)
    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    retriever = vector.as_retriever()
    return create_retriever_tool(
        retriever,
        name="pdf_search",
        description="Use this tool to search information from the pdf document",
    )

def ensure_prefix_ak(text: str) -> str:
    t = (text or "").strip()
    return t if t.startswith("ì•œ!") else f"ì•œ! {t}"

def chat_with_agent(user_input, agent_executor, session_history):
    result = agent_executor.invoke({"input": user_input,
                                    "chat_history": session_history.messages})
    return result["output"]

def get_session_history(session_id):
    if "session_history" not in st.session_state:
        st.session_state.session_history = {}
    if session_id not in st.session_state.session_history:
        st.session_state.session_history[session_id] = ChatMessageHistory()
    return st.session_state.session_history[session_id]

def print_messages():
    for msg in st.session_state.get("messages", []):
        st.chat_message(msg["role"]).write(msg["content"])

# ---------------- ê²Œì´íŠ¸ UI: ì˜¤ë„ í•´ë³‘ ì—¬ë¶€ ----------------
def marine_gate_ui():
    st.subheader("ì‚¬ì „ í™•ì¸")
    choice = st.radio(
        "ì˜¤ë„ í•´ë³‘ì…ë‹ˆê¹Œ?",
        options=["ì˜ˆ, ì˜¤ë„ í•´ë³‘ì´ë‹¤", "ì•„ë‹ˆë‹¤"],
        horizontal=True,
        key="marine_choice",
    )

    if choice == "ì•„ë‹ˆë‹¤":
        st.info("í•´ë³‘ëŒ€ì— ì…ëŒ€í•˜ê² ìŠµë‹ˆê¹Œ? ì•„ë˜ ë°•ìŠ¤ë¥¼ ì²´í¬í•´ì•¼ ì§„í–‰ ê°€ëŠ¥í•˜ë‹¤.")
        agreed = st.checkbox("ë„¤, ì…ëŒ€í•˜ê² ìŠµë‹ˆë‹¤.", key="agree_enlist")
        if agreed:
            st.success("ì…ëŒ€ í™•ì¸. ì§ˆë¬¸ ê°€ëŠ¥í•˜ë‹¤.")
        return agreed  # ì²´í¬í•´ì•¼ í†µê³¼
    return True  # ì˜¤ë„ í•´ë³‘ì´ë©´ ë°”ë¡œ í†µê³¼

def main():
    st.set_page_config(page_title="AI ë¹„ì„œ", layout="wide", page_icon="ğŸ¤–")

    with st.container():
        st.image("./chatbot_logo.png", use_container_width=True)
        st.markdown("---")
        st.title("ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ! RAGë¥¼ í™œìš©í•œ 'AI ë¹„ì„œ í†¡í†¡ì´' ì…ë‹ˆë‹¤")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input("OPENAI API í‚¤", placeholder="Enter Your API Key", type="password")
        st.session_state["SERPAPI_API"] = st.text_input("SERPAPI_API í‚¤", placeholder="Enter Your API Key", type="password")
        st.markdown("---")
        pdf_docs = st.file_uploader("Upload your PDF Files", accept_multiple_files=True, key="pdf_uploader")

    # ê²Œì´íŠ¸: ì˜¤ë„ í•´ë³‘ ì—¬ë¶€
    gate_passed = marine_gate_ui()

    if not st.session_state["OPENAI_API"]:
        st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        # ì…ë ¥ì°½ ë¹„í™œì„±í™”
        st.chat_input("ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?", disabled=True)
        return

    os.environ["OPENAI_API_KEY"] = st.session_state["OPENAI_API"]
    if st.session_state.get("SERPAPI_API"):
        os.environ["SERPAPI_API_KEY"] = st.session_state["SERPAPI_API"]

    tools = []
    if pdf_docs:
        tools.append(load_pdf_files(pdf_docs))
    if st.session_state.get("SERPAPI_API"):
        tools.append(search_web())

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "Always answer in Korean. Every response MUST start with 'ì•œ!' followed by your answer. "
         "Never omit the 'ì•œ!' prefix. "
         "You are a bold, military-style chatbot named `í˜ì„ê³  ê°•í•œ AI ë¹„ì„œ í†¡í†¡ì´`. "
         "Use firm endings (â€¦í•œë‹¤/â€¦í•˜ê² ë‹¤/â€¦í•˜ë¼/â€¦ì´ë‹¤). "
         "Pick ONE header immediately after the prefix based on context: "
         "1) ê·¸ë ‡ìŠµë‹ˆë‹¤ â€” confirm or direct answer. "
         "2) ì˜ˆ, ì•Œê² ìŠµë‹ˆë‹¤ â€” acknowledge orders. "
         "3) ë˜‘ë°”ë¡œ í•˜ê² ìŠµë‹ˆë‹¤ â€” admit mistake and commit to fix. "
         "4) ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤ â€” will investigate unknowns. "
         "5) ~ì¸ì§€ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤ â€” ask a clarifying question. "
         "Use pdf_search for PDF and web_search for web facts when necessary."
        ),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    agent = create_tool_calling_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    # ê²Œì´íŠ¸ì— ë”°ë¼ ì…ë ¥ì°½ ì ê¸ˆ
    user_input = st.chat_input("ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?", disabled=not gate_passed)

    if user_input and gate_passed:
        session_id = "default_session"
        session_history = get_session_history(session_id)

        raw = chat_with_agent(user_input, agent_executor, session_history)
        response = ensure_prefix_ak(raw)

        st.session_state["messages"].append({"role": "user", "content": user_input})
        st.session_state["messages"].append({"role": "assistant", "content": response})

        session_history.add_user_message(user_input)
        session_history.add_ai_message(response)

    print_messages()

if __name__ == "__main__":
    main()
